{"cells":[{"cell_type":"markdown","metadata":{"id":"vY-qp-cGglgc"},"source":["#   Bibliotecas"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:13:48.985446Z","iopub.status.busy":"2022-11-03T23:13:48.985044Z","iopub.status.idle":"2022-11-03T23:13:49.023266Z","shell.execute_reply":"2022-11-03T23:13:49.022351Z","shell.execute_reply.started":"2022-11-03T23:13:48.985404Z"},"id":"arnDOIXUglgi","trusted":true},"outputs":[],"source":["import pandas as pd\n","import random \n","import numpy as np\n","import re\n","from scipy.sparse import hstack #utilizada para a junção de matrizes\n","import joblib  \n","import pickle\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:13:49.025636Z","iopub.status.busy":"2022-11-03T23:13:49.024639Z","iopub.status.idle":"2022-11-03T23:13:49.748889Z","shell.execute_reply":"2022-11-03T23:13:49.747836Z","shell.execute_reply.started":"2022-11-03T23:13:49.025571Z"},"id":"z-N1W7Luglgk","trusted":true},"outputs":[],"source":["#Pré processamento de colunas\n","\n","from sklearn.model_selection import train_test_split #Divisão do dataset entre treino e teste\n","from sklearn.feature_extraction.text import TfidfVectorizer #vetorização do dataset\n","from sklearn.preprocessing import OneHotEncoder, FunctionTransformer #aplicação de dummy\n","\n","from sklearn.compose import make_column_transformer\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-11-03T23:13:49.751047Z","iopub.status.busy":"2022-11-03T23:13:49.750634Z","iopub.status.idle":"2022-11-03T23:13:50.400422Z","shell.execute_reply":"2022-11-03T23:13:50.399231Z","shell.execute_reply.started":"2022-11-03T23:13:49.751009Z"},"id":"_JBIjHQ6glgm","outputId":"b12e9c1f-ed1f-4f87-8c89-25a819583ed9","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#Pré processamento de texto\n","\n","import nltk\n","from nltk import word_tokenize #tokenizador\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords   #stopword\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","stop_words = stopwords.words('english')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:13:50.402577Z","iopub.status.busy":"2022-11-03T23:13:50.401983Z","iopub.status.idle":"2022-11-03T23:13:55.481548Z","shell.execute_reply":"2022-11-03T23:13:55.480445Z","shell.execute_reply.started":"2022-11-03T23:13:50.402538Z"},"id":"JAsKT1rxglgo","trusted":true},"outputs":[],"source":["#import de funções do arquivo pre_processamento\n","\n","from pre_processamento import pre_processamento"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-11-03T23:13:55.483885Z","iopub.status.busy":"2022-11-03T23:13:55.483022Z","iopub.status.idle":"2022-11-03T23:13:55.488638Z","shell.execute_reply":"2022-11-03T23:13:55.487667Z","shell.execute_reply.started":"2022-11-03T23:13:55.483848Z"},"id":"-R8qJsJXglgp","outputId":"3c0747ac-8c7e-4ea5-f1a3-9fc6c4333e80","trusted":true},"outputs":[],"source":["# Modelo a ser testado\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from keras.layers import Input, Dense, Concatenate, Dropout, Reshape, Conv1D\n","from keras.layers import BatchNormalization, Activation, Flatten, MaxPooling1D\n","from keras.models import Model\n","from keras.metrics import RootMeanSquaredError\n","from keras.utils import plot_model\n","from keras.optimizers import Adam\n","from keras.models import load_model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:13:55.491699Z","iopub.status.busy":"2022-11-03T23:13:55.490080Z","iopub.status.idle":"2022-11-03T23:13:55.506538Z","shell.execute_reply":"2022-11-03T23:13:55.505333Z","shell.execute_reply.started":"2022-11-03T23:13:55.491654Z"},"trusted":true},"outputs":[],"source":["#metricas\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:13:55.511313Z","iopub.status.busy":"2022-11-03T23:13:55.511003Z","iopub.status.idle":"2022-11-03T23:13:55.901963Z","shell.execute_reply":"2022-11-03T23:13:55.900799Z","shell.execute_reply.started":"2022-11-03T23:13:55.511288Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(r\"C:\\Users\\angel\\Desktop\\bootcamp\\train.tsv\", sep='\\t')\n","test = pd.read_csv(r\"C:\\Users\\angel\\Desktop\\bootcamp\\test_stg2.tsv\", sep='\\t')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:13:55.903776Z","iopub.status.busy":"2022-11-03T23:13:55.903374Z","iopub.status.idle":"2022-11-03T23:13:55.920283Z","shell.execute_reply":"2022-11-03T23:13:55.919300Z","shell.execute_reply.started":"2022-11-03T23:13:55.903738Z"},"trusted":true},"outputs":[],"source":["train,test = pre_processamento(train,test)"]},{"cell_type":"markdown","metadata":{},"source":["#   Funções para Feature engineering"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#Função pra juntar as colunas de texto em uma só\n","def textcolumns(df):\n","\n","      #Preenchendo valores nulos com espaço em branco.\n"," \n","    \n","    df['name'].fillna(' ', inplace=True)\n","    df['brand_name'].fillna(' ', inplace=True)\n","    df['item_description'].fillna(' ', inplace=True)                \n","       \n","\n","    #concatenando                              \n","    df[\"item_description\"] =  df[\"name\"]+\" \"+df[\"brand_name\"]+\" \"+ df[\"item_description\"]\n","    \n","    #convertendo string\n","    df[\"item_description\"] = df[\"item_description\"].astype(str)\n","                                 \n","                            \n","    #Removendo colunas que não serão usadas no modelo\n","    df = df.drop([  \"name\",\n","                    \"brand_name\",\n","                    \"category_name\",\n","                    \"stock\",\n","                    \"datetime_month\",\n","                    \"datetime_year\"   ], axis = 1)\n","                    \n","    return df\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["   #Função para \"separação\" de palavras, ex: Can't -> can not, objetivo de facilitar a limpeza, aonde não serão criadas duas palavras para cant/can not.\n","    # Será feito para diversas palavras com a mesma condição.\n","def text_clean(phrase):\n","\n","    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n","    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n","    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n","    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n","    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n","    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n","    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n","    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n","    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n","    \n","    phrase = re.sub('https?://\\S+| www.\\S+', ' ', phrase) #Remoção de qualquer site que possa ter no nosso dataset\n","    phrase = re.sub(\"[^a-zA-Z0-9' \\n\\.]\", ' ', phrase)  #excluindo tudo o que não for letra e numero.\n","    phrase = re.sub(r'([a-z0-9])\\1{2,}', \" \", phrase) #retirando letras repetidas mais de 2 vezes seguidas ex: \"ele vaaai\" -> \"ele vai\"\n","    phrase = re.sub(r'\\s+[0-9]{3,}\\s+', \" \", phrase)  # removendo numeros muito grandes com 3 digitos ou mais\n","    phrase = re.sub(r'\\s+([a-zA-Z])\\1{1,}\\s+', \" \", phrase) #removendo letras repetidas isoladas ex: ele zz vai -> ele vai\n","    phrase= re.sub(r'[^\\w\\s]', '', phrase)\n","    \n","    \n","    phrase = re.sub(' +', ' ', phrase) #exclusão de espaços extras, ex: \"eu    vou\" -> \"eu vou\"\n","\n","    phrase = phrase.lower() #passando para letra minúscula.\n","\n","   \n","    return phrase\n","    "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def stemming(text):\n","    porter = PorterStemmer()\n","    stop_words = stopwords.words('english')\n","    \n","    result=[]\n","    for word in text:\n","        if word not in stop_words:\n","            result.append(porter.stem(word))\n","    return result"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["def vectorize_data(df, vec=None):\n","    \"\"\"\n","    Função para vetorizar a coluna item_description e salvar o fit\n","\n","    input: df escolhido \n","           vec = None para gerar um vetorizador\n","           caso já tenha sido feito o fit, passa-lo no parametro vec\n","\n","    output: coluna vetorizada e o fit salvo para utiliza-lo\n","    \n","    \"\"\"\n","    if vec==None:\n","        vec = TfidfVectorizer(ngram_range=(1,2), max_features=50000)\n","        vec.fit(df[\"item_description\"])\n","    tfid_data = vec.transform(df[\"item_description\"])\n","    return tfid_data, vec"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["def onehot_data(df, ohe=None):\n","\n","    \"\"\"\n","    Função para one hot enconde nas colunas e salvar o fit\n","\n","    input: df escolhido \n","           ohe = None para gerar um fit\n","           caso já tenha sido feito o fit, passa-lo no parametro ohe\n","\n","    output: matriz e o fit salvo para utiliza-lo\n","    \n","    \"\"\"\n","    if ohe==None:\n","        ohe = OneHotEncoder(handle_unknown=\"ignore\")\n","        ohe.fit(df[[\"item_condition_id\",   \n","                   \"shipping\",\n","                   \"sub1_cat\",\n","                   \"sub2_cat\"]])\n","\n","    ohe_data = ohe.transform(df[[\"item_condition_id\",   \n","                                \"shipping\",\n","                                \"sub1_cat\",\n","                                \"sub2_cat\"]])\n","\n","    return ohe_data, ohe"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["#função para juntar a vetorização do tfidf e a matrix do onehotencoder, retorna uma matriz.\n","\n","def stack(vec, ohe):\n","    xstack = (hstack([vec, ohe],format='csr'))\n","    xstack.sort_indices()\n","\n","    return xstack"]},{"cell_type":"markdown","metadata":{},"source":["#   Pipeline de pré-processamento"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["\n","'''Função de pipeline para o pré processamento\n","\n","    input: O df à ser pré-processado, para gerar um fit do tfidf e do onehot enconder, manter vec e ohe = None.\n","           Para apenas um transform, passar os fit gerados nos parametros vec e ohe.\n","    \n","    Output: df = Retorna o df pré processado, \n","            vec_data = matriz gerada no vectorizer\n","            vec = fit salvo do vectorizer\n","            ohe_data = matriz gerada pelo one hot\n","            ohe = fit salvo do one hot\n","            x_stack = juntando vec_data e Ohe_data em uma matriz.\n","\n","    obs: Caso esteja apenas transformando, vec e ohe de saida serão os mesmos da entrada, se mantendo com o fit original.   \n","'''\n","\n","def feature_eng(df, vec=None, ohe=None):\n","\n","    print()\n","    print(\"Juntando e preparando colunas de texto...\")\n","    df = textcolumns(df)\n","\n","    print(\"Aplicando Regex!...\")\n","    df[\"item_description\"] = df[\"item_description\"].apply(lambda x: text_clean(x))\n","\n","    print(\"Tokenizando...\")\n","    df[\"item_description\"] = df[\"item_description\"].apply(lambda x: word_tokenize(x))\n","\n","    print(\"Realizando Stemming...\")\n","    df[\"item_description\"] = df[\"item_description\"].apply(lambda x: stemming(x))\n","\n","    print(\"join...\")\n","    df[\"item_description\"]=[\" \".join(review) for review in df[\"item_description\"].values]\n","\n","    print(\"Aplicando Tfidf...\")\n","    vec_data, vec = vectorize_data(df, vec)\n","\n","    print(\"Aplicando ohe...\")\n","    ohe_data, ohe = onehot_data(df, ohe)\n","    \n","    print(\"Juntando matriz Tfidf e Ohe...\")\n","    x_stack = stack(vec_data, ohe_data)\n","\n","    print(\"Finalizado!\")\n","\n","    return df, vec_data, vec, ohe_data, ohe, x_stack"]},{"cell_type":"markdown","metadata":{"id":"0heeefYUOg3T"},"source":["#   Split"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:14:16.727741Z","iopub.status.busy":"2022-11-03T23:14:16.727253Z","iopub.status.idle":"2022-11-03T23:14:17.688823Z","shell.execute_reply":"2022-11-03T23:14:17.687679Z","shell.execute_reply.started":"2022-11-03T23:14:16.727694Z"},"id":"C68U4qcbOg3U","trusted":true},"outputs":[],"source":["treino1, teste = train_test_split(train, test_size=0.1, random_state=10) #Divisão em 90/10"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:14:17.691796Z","iopub.status.busy":"2022-11-03T23:14:17.690895Z","iopub.status.idle":"2022-11-03T23:14:18.647970Z","shell.execute_reply":"2022-11-03T23:14:18.646718Z","shell.execute_reply.started":"2022-11-03T23:14:17.691735Z"},"id":"iNAQUKMUOg3V","trusted":true},"outputs":[],"source":["#Separação em treino e teste para começarmos as transformaçõs, protegendo nossos dados de validação de possíveis vazamentos. \n","\n","treino, val = train_test_split(treino1, test_size=0.2, random_state=10) #Divisão em 80/20"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:14:18.659319Z","iopub.status.busy":"2022-11-03T23:14:18.658533Z","iopub.status.idle":"2022-11-03T23:14:18.671027Z","shell.execute_reply":"2022-11-03T23:14:18.669383Z","shell.execute_reply.started":"2022-11-03T23:14:18.659282Z"},"id":"USZkzeN5Og3X","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1066795, 13)\n","(266699, 13)\n","(148167, 13)\n"]}],"source":["print(treino.shape) \n","print(val.shape)\n","print(teste.shape)"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["#função para separar o dataset no range de valor.\n","\n","def price_range(df, minimo, maximo):\n","    df = df.loc[(df['price'] > minimo) & (df['price'] <= maximo),]\n","    \n","    return df"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["treino = price_range(treino, 0, 250)"]},{"cell_type":"markdown","metadata":{"id":"rV15T9YsOg3N"},"source":["#   Pré-processamento Treino"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["treino, vec_treino, vec, ohe_treino, ohe, x_train = feature_eng(treino, None, None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ytrain = treino[\"price\"]\n","ytrain = np.log1p(ytrain)\n","Xtrain = treino.drop(\"price\", axis=1)\n","Xtrain.shape"]},{"cell_type":"markdown","metadata":{},"source":["#   Pré-processamento Validação"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["val = price_range(val, minimo, maximo)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["val, vec_val, vec, ohe_val, ohe, x_val = feature_eng(val, vec=vec, ohe=ohe)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_val"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["yval = val[\"price\"]\n","yval = np.log1p(yval)\n","Xval = val.drop(\"price\", axis=1)\n","Xval.shape"]},{"cell_type":"markdown","metadata":{},"source":["#   Joblib pré processamento"]},{"cell_type":"markdown","metadata":{},"source":["-   Treino"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["joblib.dump(vec,(\"tfidf1.pkl\"))\n","joblib.dump(ohe,(\"ohe.pkl\"))\n","\n","joblib.dump(vec_treino,(\"vec_treino\"))\n","joblib.dump(ohe_treino,(\"ohe_treino.pkl\"))\n","joblib.dump(x_train,(\"x_train.pkl\"))\n","\n","treino.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtrain.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#vec= joblib.load((\"tfidf1.pkl\"))\n","#ohe= joblib.load((\"ohe.pkl\"))\n","\n","#vec_treino = joblib.load((\"vec_treino\"))\n","#ohe_treino = joblib.load((\"ohe_treino.pkl\"))\n","#x_train = joblib.load((\"x_train.pkl\"))\n","\n","#treino = pd.read_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtrain.pkl\")"]},{"cell_type":"markdown","metadata":{},"source":["-   Validação"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["joblib.dump(vec_val,(\"vec_val\"))\n","joblib.dump(ohe_val,(\"ohe_val.pkl\"))\n","joblib.dump(x_val,(\"x_val.pkl\"))\n","\n","treino.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xval.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#vec_val = joblib.load((\"vec_treino\"))\n","#ohe_val = joblib.load((\"ohe_treino.pkl\"))\n","#x_val = joblib.load((\"x_val.pkl\"))\n","\n","#val = pd.read_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xval.pkl\")"]},{"cell_type":"markdown","metadata":{"id":"y10XXPRKOxdL"},"source":["# Modelo"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T23:44:56.990995Z","iopub.status.busy":"2022-11-03T23:44:56.990489Z","iopub.status.idle":"2022-11-03T23:44:57.014687Z","shell.execute_reply":"2022-11-03T23:44:57.013505Z","shell.execute_reply.started":"2022-11-03T23:44:56.990952Z"},"id":"sE2crBXWglg4","trusted":true},"outputs":[],"source":["from keras.backend import clear_session\n","\n","clear_session()"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["def mlp_model(input_shape, activation, dropout):\n","    input = Input(shape=(input_shape.shape[-1]), sparse=True, name='sparse')\n","    out = Dense(1024, activation=activation) (input)\n","    out = Dropout(dropout)(out)\n","    out = Dense(1024, activation=activation) (out)\n","    out = Dropout(dropout)(out)\n","    out = Dense(1024, activation=activation) (out)\n","    out = Dense(1) (out)\n","\n","    model = Model( input, out)\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-11-03T23:44:57.018898Z","iopub.status.busy":"2022-11-03T23:44:57.018528Z","iopub.status.idle":"2022-11-03T23:44:59.867115Z","shell.execute_reply":"2022-11-03T23:44:59.865885Z","shell.execute_reply.started":"2022-11-03T23:44:57.018866Z"},"id":"CRuJRa0Pglg4","outputId":"e3a40432-1437-4cdc-9a2e-860b0b0785f7","trusted":true},"outputs":[],"source":["model = mlp_model(x_train[-1], \"relu\", 0.2)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-11-03T23:44:59.881482Z","iopub.status.busy":"2022-11-03T23:44:59.881200Z","iopub.status.idle":"2022-11-04T00:04:49.110988Z","shell.execute_reply":"2022-11-04T00:04:49.109846Z","shell.execute_reply.started":"2022-11-03T23:44:59.881442Z"},"id":"UVrki0shglg4","outputId":"aa850195-660d-461d-ae14-76b8cd276147","trusted":true},"outputs":[],"source":["\n","\n","model.compile(loss=\"mean_squared_error\", metrics=['mean_squared_error', \n","                                                  'mean_squared_logarithmic_error'],                                                          \n","                                                  optimizer = Adam(learning_rate = 0.0005))\n","\n","\n","\n","model.fit(x_train, ytrain.values,\n","        batch_size=1024, epochs=10,\n","        verbose=True, \n","        validation_data = (x_val, yval))\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save(\"keras_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = keras.models.load_model(\"keras_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#vec= joblib.load((\"tfidf1.pkl\"))\n","#ohe= joblib.load((\"ohe.pkl\"))"]},{"cell_type":"markdown","metadata":{},"source":["#   Teste"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["teste_ = teste[].copy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["teste_ = price_range(teste_, minimo, maximo)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["teste_, vec_teste, vec, ohe_teste, ohe, x_teste = feature_eng(teste_, vec=vec, ohe=ohe)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_teste"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["yteste = teste[\"price\"]\n","yteste = np.log1p(yteste)\n","Xteste = teste.drop(\"price\", axis=1)\n","Xteste.shape"]},{"cell_type":"markdown","metadata":{},"source":["#   Métricas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def metrics(model, X_data, y_data):\n","    ypred = model.predict(X_data)\n","    ypred = np.expm1(ypred)\n","\n","    print('MAE: $ %.2f' %  mean_absolute_error(y_data,ypred))\n","    print('RMSE:  $ %.2f' %  (mean_squared_error(y_data,ypred)**0.5))\n","    print('RMSLE: %2f' % mean_squared_log_error(y_data,ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics(model, )"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 ('blue_bootcamp': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"0cba9dc48216265c7a67d52538187b6a360d3b2963a1f5a8f0947f5a3cb43c1c"}}},"nbformat":4,"nbformat_minor":4}
