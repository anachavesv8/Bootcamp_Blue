{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versões das bibliotecas no README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.sparse import hstack #utilizada para a junção de matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pré processamento de colunas\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Divisão do dataset entre treino e teste\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #vetorização do dataset\n",
    "from sklearn.preprocessing import OneHotEncoder #aplicação de dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pré processamento de texto\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize #tokenizador\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords   #stopword\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import de funções do script de pre_processamento\n",
    "\n",
    "from pre_processamento import pre_processamento, text_preprocess, textcolumns_junct,stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo a ser testado\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metricas\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9340559379129461765\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2252026676\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16652033083150953189\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\angel\\Desktop\\bootcamp\\train.tsv\", sep='\\t')\n",
    "test = pd.read_csv(r\"C:\\Users\\angel\\Desktop\\bootcamp\\test_stg2.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = pre_processamento(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separação em treino e teste para começarmos as transformações, protegendo nossos dados de teste de possíveis vazamentos e das mudanças de hyperparametros. \n",
    "\n",
    "X1, Xtest = train_test_split(train, test_size=0.1, random_state=10) #Divisão em 90/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separação em treino e teste para começarmos as transformaçõs, protegendo nossos dados de validação de possíveis vazamentos. \n",
    "\n",
    "Xtrain, Xval = train_test_split(X1, test_size=0.2, random_state=10) #Divisão em 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066795, 13)\n",
      "(266699, 13)\n",
      "(148167, 13)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape) \n",
    "print(Xval.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Pré-processamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função pra juntar as colunas de texto em uma só coluna\n",
    "\n",
    "Xtrain = textcolumns_junct(Xtrain) \n",
    "Xval = textcolumns_junct(Xval) \n",
    "Xtest = textcolumns_junct(Xtest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo tudo para string\n",
    "\n",
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].astype(str)\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].astype(str)\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando texto com regex.\n",
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].apply(lambda x: text_preprocess(x))\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].apply(lambda x: text_preprocess(x))\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].apply(lambda x: text_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizando\n",
    "\n",
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].apply(lambda x: word_tokenize(x))\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].apply(lambda x: word_tokenize(x))\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].apply(lambda x: stemming(x))\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].apply(lambda x: stemming(x))\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain[\"item_description\"]=[\" \".join(review) for review in Xtrain[\"item_description\"].values]\n",
    "Xval[\"item_description\"]=[\" \".join(review) for review in Xval[\"item_description\"].values]\n",
    "Xtest[\"item_description\"]=[\" \".join(review) for review in Xtest[\"item_description\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         No description yet\n",
       "1          This keyboard is in great condition and works ...\n",
       "2          Adorable top with a hint of lace and a key hol...\n",
       "3          New with tags. Leather horses. Retail for [rm]...\n",
       "4                  Complete with certificate of authenticity\n",
       "                                 ...                        \n",
       "1482530    Lace, says size small but fits medium perfectl...\n",
       "1482531     Little mermaid handmade dress never worn size 2t\n",
       "1482532            Used once or twice, still in great shape.\n",
       "1482533    There is 2 of each one that you see! So 2 red ...\n",
       "1482534    New with tag, red with sparkle. Firm price, no...\n",
       "Name: item_description, Length: 1481661, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"item_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtrain.pkl\")\n",
    "#Xval.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xval.pkl\")\n",
    "#Xtest.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treinando o modelo com valores até $250, que representam 89% do dataset\n",
    "Xtrain = Xtrain.drop(Xtrain[~((Xtrain['price'] > 0) & (Xtrain['price'] <= 250))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xtrain.drop(\"price\", axis = 1)\n",
    "y = Xtrain[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xval.drop(\"price\", axis = 1)\n",
    "y = Xval[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xtest.drop(\"price\", axis = 1)\n",
    "y = Xtest[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformadores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('blue_bootcamp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cba9dc48216265c7a67d52538187b6a360d3b2963a1f5a8f0947f5a3cb43c1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
