{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versões das bibliotecas no README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.sparse import hstack #utilizada para a junção de matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pré processamento de colunas\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Divisão do dataset entre treino e teste\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #vetorização do dataset\n",
    "from sklearn.preprocessing import OneHotEncoder #aplicação de dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pré processamento de texto\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize #tokenizador\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords   #stopword\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import de funções do script de pre_processamento\n",
    "\n",
    "from pre_processamento import pre_processamento, text_preprocess, textcolumns_junct,stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo a ser testado\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metricas\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8972256609375542872\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2252026676\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10233264540272622807\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\angel\\Desktop\\bootcamp\\train.tsv\", sep='\\t')\n",
    "test = pd.read_csv(r\"C:\\Users\\angel\\Desktop\\bootcamp\\test_stg2.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = pre_processamento(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separação em treino e teste para começarmos as transformações, protegendo nossos dados de teste de possíveis vazamentos e das mudanças de hyperparametros. \n",
    "\n",
    "X1, Xtest = train_test_split(train, test_size=0.1, random_state=10) #Divisão em 90/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separação em treino e teste para começarmos as transformaçõs, protegendo nossos dados de validação de possíveis vazamentos. \n",
    "\n",
    "Xtrain, Xval = train_test_split(X1, test_size=0.2, random_state=10) #Divisão em 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066795, 13)\n",
      "(266699, 13)\n",
      "(148167, 13)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape) \n",
    "print(Xval.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Pré-processamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função pra juntar as colunas de texto em uma só coluna\n",
    "\n",
    "Xtrain = textcolumns_junct(Xtrain) \n",
    "Xval = textcolumns_junct(Xval) \n",
    "Xtest = textcolumns_junct(Xtest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo tudo para string\n",
    "\n",
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].astype(str)\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].astype(str)\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando texto com regex.\n",
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].apply(lambda x: text_preprocess(x))\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].apply(lambda x: text_preprocess(x))\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].apply(lambda x: text_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizando\n",
    "\n",
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].apply(lambda x: word_tokenize(x))\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].apply(lambda x: word_tokenize(x))\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain[\"item_description\"] = Xtrain[\"item_description\"].apply(lambda x: stemming(x))\n",
    "Xval[\"item_description\"] = Xval[\"item_description\"].apply(lambda x: stemming(x))\n",
    "Xtest[\"item_description\"] = Xtest[\"item_description\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain[\"item_description\"]=[\" \".join(review) for review in Xtrain[\"item_description\"].values]\n",
    "Xval[\"item_description\"]=[\" \".join(review) for review in Xval[\"item_description\"].values]\n",
    "Xtest[\"item_description\"]=[\" \".join(review) for review in Xtest[\"item_description\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtrain.pkl\")\n",
    "#Xval.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xval.pkl\")\n",
    "#Xtest.to_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.read_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtrain.pkl\")\n",
    "Xval = pd.read_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xval.pkl\") \n",
    "Xtest = pd.read_pickle(r\"C:\\Users\\angel\\Desktop\\bootcamp\\Xtest.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treinando o modelo com valores até $250, que representam 89% do dataset\n",
    "Xtrain = Xtrain.drop(Xtrain[~((Xtrain['price'] > 0) & (Xtrain['price'] <= 250))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>stock</th>\n",
       "      <th>gen_cat</th>\n",
       "      <th>sub1_cat</th>\n",
       "      <th>sub2_cat</th>\n",
       "      <th>datetime_month</th>\n",
       "      <th>datetime_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743320</th>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Face</td>\n",
       "      <td>1</td>\n",
       "      <td>new face sweetheart blush bronzer face face bu...</td>\n",
       "      <td>11</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>Makeup</td>\n",
       "      <td>Face</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313184</th>\n",
       "      <td>1</td>\n",
       "      <td>Vintage &amp; Collectibles/Supplies/Fabric</td>\n",
       "      <td>1</td>\n",
       "      <td>bundl 6 red ish fabric clearanc size vari 1 ya...</td>\n",
       "      <td>15</td>\n",
       "      <td>Vintage &amp; Collectibles</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>Fabric</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367929</th>\n",
       "      <td>1</td>\n",
       "      <td>Men/Men's Accessories/Hats</td>\n",
       "      <td>1</td>\n",
       "      <td>suprem camo facemask suprem brand new free shi...</td>\n",
       "      <td>4</td>\n",
       "      <td>Men</td>\n",
       "      <td>Men's Accessories</td>\n",
       "      <td>Hats</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41968</th>\n",
       "      <td>1</td>\n",
       "      <td>Beauty/Makeup/Makeup Sets</td>\n",
       "      <td>1</td>\n",
       "      <td>ipsi bag makeup brush sephora ipsi cosmet bag ...</td>\n",
       "      <td>19</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>Makeup</td>\n",
       "      <td>Makeup Sets</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633793</th>\n",
       "      <td>1</td>\n",
       "      <td>Women/Swimwear/One-Piece</td>\n",
       "      <td>0</td>\n",
       "      <td>new acacia bronx one piec heliconia acacia swi...</td>\n",
       "      <td>17</td>\n",
       "      <td>Women</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>One-Piece</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_condition_id                           category_name  shipping  \\\n",
       "743320                   1                      Beauty/Makeup/Face         1   \n",
       "313184                   1  Vintage & Collectibles/Supplies/Fabric         1   \n",
       "1367929                  1              Men/Men's Accessories/Hats         1   \n",
       "41968                    1               Beauty/Makeup/Makeup Sets         1   \n",
       "633793                   1                Women/Swimwear/One-Piece         0   \n",
       "\n",
       "                                          item_description  stock  \\\n",
       "743320   new face sweetheart blush bronzer face face bu...     11   \n",
       "313184   bundl 6 red ish fabric clearanc size vari 1 ya...     15   \n",
       "1367929  suprem camo facemask suprem brand new free shi...      4   \n",
       "41968    ipsi bag makeup brush sephora ipsi cosmet bag ...     19   \n",
       "633793   new acacia bronx one piec heliconia acacia swi...     17   \n",
       "\n",
       "                        gen_cat           sub1_cat     sub2_cat  \\\n",
       "743320                   Beauty             Makeup         Face   \n",
       "313184   Vintage & Collectibles           Supplies       Fabric   \n",
       "1367929                     Men  Men's Accessories         Hats   \n",
       "41968                    Beauty             Makeup  Makeup Sets   \n",
       "633793                    Women           Swimwear    One-Piece   \n",
       "\n",
       "         datetime_month  datetime_year  \n",
       "743320              1.0         2018.0  \n",
       "313184             10.0         2018.0  \n",
       "1367929             4.0         2018.0  \n",
       "41968              11.0         2018.0  \n",
       "633793              9.0         2018.0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1062337, 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = Xtrain[\"price\"]\n",
    "Xtrain = Xtrain.drop(\"price\", axis=1)\n",
    "Xtrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266699, 10)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yval= Xval[\"price\"]\n",
    "Xval = Xval.drop(\"price\", axis = 1)\n",
    "Xval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148167, 10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = Xtest[\"price\"]\n",
    "Xtest = Xtest.drop(\"price\", axis = 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_condition_id', 'category_name', 'shipping', 'item_description',\n",
       "       'stock', 'gen_cat', 'sub1_cat', 'sub2_cat', 'datetime_month',\n",
       "       'datetime_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#input para shipping\n",
    "input_shipping = layers.Input(shape=)\n",
    "hidden1_shipping = layers.Dense(512,activation=\"relu\")(input_shipping)\n",
    "\n",
    "#input para item_description\n",
    "input_item_description = layers.Input(shape=)\n",
    "hidden1_item_description = layers.Dense(512,activation=\"relu\")(input_item_description)\n",
    "drop1_item_description = layers.Dropout(0.2)(hidden1_item_description)\n",
    "hidden2_item_description = layers.Dense(512,activation=\"relu\")(drop1_item_description)\n",
    "\n",
    "#input para gen_cat\n",
    "input_gen_cat= layers.Input(shape=)\n",
    "hidden1_gen_cat = layers.Dense(512,activation=\"relu\")(input_gen_cat)\n",
    "\n",
    "#input para sub1_cat\n",
    "input_sub1_cat = layers.Input(shape=)\n",
    "hidden1_sub1_cat = layers.Dense(512,activation=\"relu\")(input_sub1_cat)\n",
    "\n",
    "#input para sub2_cat\n",
    "input_sub2_cat = layers.Input(shape=)\n",
    "hidden1_sub2_cat = layers.Dense(512,activation=\"relu\")(input_sub2_cat)\n",
    "\n",
    "#Concatenando \n",
    "concat = layers.Concatenate()([hidden1_shipping, \n",
    "                             hidden2_item_description,\n",
    "                             hidden1_gen_cat,\n",
    "                             hidden1_sub1_cat,\n",
    "                             hidden1_sub2_cat])\n",
    "\n",
    "#Adicionando Layer à saida do concat\n",
    "\n",
    "hidden1 = layers.Dense(512,activation=\"relu\")(concat)\n",
    "drop1 = layers.Dropout(0.2)(hidden1)\n",
    "hidden2 = layers.Dense(512,activation=\"relu\")(drop1)\n",
    "drop2 = layers.Dropout(0.2)(hidden2)\n",
    "\n",
    "#Saida\n",
    "output = layers.Dense(1, activation=\"relu\")(drop2)\n",
    "\n",
    "#Modelo\n",
    "model = Model(inputs = [input_shipping,\n",
    "                        input_item_description,\n",
    "                        input_gen_cat,\n",
    "                        input_sub1_cat,\n",
    "                        input_sub2_cat], \n",
    "                                          outputs = output)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.utils.plot_model(model, to_file=\"my_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", \n",
    "              metrics=['mean_squared_error', RootMeanSquaredError()], \n",
    "              optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history =  model.fit(Xtrain,\n",
    "                     ytrain.values, \n",
    "                     batch_size=2048,\n",
    "                     epochs=25, \n",
    "                     verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('blue_bootcamp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cba9dc48216265c7a67d52538187b6a360d3b2963a1f5a8f0947f5a3cb43c1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
